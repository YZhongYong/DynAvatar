train{
    # folder structure: exps_folder/subject/methodname/train_split/train/[checkpoints, saved conf]
    #                                                             /eval/test_split/step/image_folders
    exps_folder = /home/M2/data/experiments/ # location of experiments folder, use ln -s to link to data disk
    methodname = 2dgs
    dataset_class = datasets.real_dataset.FaceDataset
    learning_rate = 1.0e-4
    learning_rate_cam = 5.0e-4
    num_pixels = 2048
    max_points_training = 102400 # max number of points calculated during training (num_batch * num_points), reduce this if memory is limited.
    max_batch = 8
    upsample_freq = 1 # upsample is performed every 5 epochs, if number of points won't exceed point_cloud.max_points
    plot_freq = 1
    sched_milestones = [80, 100] # decay learning rate in these epochs
    sched_factor = 0.5
    GT_lbs_milestones = [20, 30, 50, 70] # decay flame regularization in these epcohs
    GT_lbs_factor = 0.5
    optimize_expression=True # optimize flame expressions
    optimize_camera=True # optimize camera and flame poses, this is important for alignment and numerical results...
}
loss{
    lbs_weight = 10.0
    eikonal_weight = 0.1
    sdf_consistency_weight =1.0
    vgg_feature_weight = 0.1
}
dataset{
    data_folder = /home/M2/data/dataset
    subject_name = level_3
    json_name = flame_params.json
    use_mean_expression=True # canonical expression is set to the mean expression of the training dataset
    use_var_expression=True # used for blendshape regularization. Apply less regularization when expression variance is large.
    canonical_pose=0.4 # canonical pose is set to zero, except the jaw opening
    train{
        sub_dir = [fear_level_3_001,fear_level_3_002,fear_level_3_007,happy_level_3_009,happy_level_3_002,sad_level_3_005,happy_level_3_007,fear_level_3_006,happy_level_3_005,fear_level_3_009,sad_level_3_004,fear_level_3_003,sad_level_3_001,sad_level_3_009,sad_level_3_006,happy_level_3_006,sad_level_3_008,happy_level_3_001,happy_level_3_004,fear_level_3_004,fear_level_3_008,happy_level_3_003,sad_level_3_003,sad_level_3_002,fear_level_3_005,happy_level_3_008,sad_level_3_007]
        img_res = [512, 512]
        subsample = 1
        load_images = True
    }
    test{
        sub_dir = [sad_level_3_010,happy_level_3_010,fear_level_3_010]
        img_res = [512, 512]
        subsample=  200
        load_images = True
    }
}
model{
    prune_thresh=0.1
    geometry_network
    {
        d_in = 3
        d_out = 1
        feature_vector_size = 3
        dims = [256, 256, 256, 256, 256, 256, 256]
        geometric_init = True
        bias = 0.6
        skip_in = [3]
        weight_norm = True
        multires = 6
    }
    rendering_network
    {
        d_in = 3
        feature_vector_size = 0
        d_out = 3
        dims = [64, 64]
        weight_norm = True
        multires_view = 0
        multires_pnts = 0
    }
    gaussian_network
    {
        d_in = 3
        feature_vector_size = 0
        d_out = 8
        dims = [64, 64, 64]
        weight_norm = True
        multires_view = 0
        multires_pnts = 0
    }
    deformer_network
    {
        d_in = 3
        dims = [128, 128, 128, 128]
        weight_norm = True
        multires = 0
	    num_exp = 50
	    ghostbone = True
	    deform_c = True
    }
    point_cloud
    {
        n_init_points=400
        max_points=100000 # max number of points for the canonical model, reduce this if memory is limited.
    }
}